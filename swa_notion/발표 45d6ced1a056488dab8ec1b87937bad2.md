# 발표

1. 프로젝트 소개

[메인페이지 화면] [1번]

안녕하세요 2조 발표자 장진혁입니다. 

항해99 2조 챌린지 프로젝트 발표를 시작하겠습니다. 

<약 10초 소요> 

[목차 화면] [2번]

발표 순서는 프로젝트 소개, 주요 기능. 아키텍처, 트러블 슈팅, 성능개선 순으로 진행하겠습니다.

<약 3초 + 3초 소요> 

[프로젝트 소개] + 기획 [3번]

저희 프로젝트 기획의도는 누구나 빠르고 쉽게 티켓 예매를 할 수 있는 사이트입니다.

<약 8초>

[프로잭트 소개] - 목표 [4번]. Transaction Per Second

프로젝트 목표는 대규모 트랜잭션 환경에서도 안정적인 서비스를 제공하기 위해 50k이상의 트랜잭션처리, 1000TPS이상 이라는 목표를 설정하고 진행했습니다.

<약 10초> 

[주요기능] [5번]

(메인페이지 → 검색 → 예매불가공연상세 → 예매가능공연 상세 → 예매하기 → 마이페이지 → 예매취소 → 관리자로그인 → 공연추가 → 추가한공연 검색)

시연 영상 먼저 보여드리겠습니다.  - 영상재생 1분 

다음은 주요기능 시연영상입니다.

neticket 메인 페이지에서는 예매가능한 공연이 오늘 날짜와 가장 가까운 순서대로 4개씩 정렬이 됩니다. 공연 검색기능은 원하는 키워드를 입력하면 제목과 장소에서 일치하는 공연들을 모아서 날짜와 예매가능한 공연부터 정렬이 되어 검색됩니다. 이미 종료된 공연이나 아직 티켓팅이 시작되지 않은 공연은 예매가 불가능합니다. 티켓팅이 시작된 공연을 클릭하면 공연에 대한 상세정보를 알 수 있고 예매를 진행하여 티켓장수를 선택 후 예매를 완료 할 수 있습니다. 예매가 완료되면 예매한 공연의 자세한 정보를 알 수 있습니다.

예매한 공연은 마이페이지에서 자세히 확인 가능하며 공연 날짜가 지나지 않은 공연만 예매 취소가 가능합니다.

관리자 계정으로 로그인하면 공연추가 버튼이 활성화되고, 관리자 페이지안으로 들어가면 Redis 캐시에 장애가 생겨 남은 좌석 수 데이터의 무결성이 깨질 경우 이를 올바른 값으로 맞춰주는 기능이 있습니다.

그리고 공연 추가를 위한 정보입력란과 이미지를 첨부하여 등록이 가능합니다.

<약 1분 10초> 

[아키텍처] [6번]

저희 프로젝트는 최적의 성능 개선을 위해 다음과 같은 아키텍처로 설계하였습니다.

애플리케이션 배포 및 확장 과정을 효율적으로 개선하기 위해 Github Action과 Docker를 사용하였으며, 이를 통해 개발, 테스트, 운영 상태를 일관성 있게 유지할 수 있습니다. 

데이터베이스는 AWS RDS MySQL을 사용하고 있으며, 응답속도를 개선하기 위해 AWS에서 제공하는 ElastiCache Redis를 활용하고 있습니다. 

서버 부하에 따라 EC2 인스턴스가 자동으로 확장되도록 Auto Scaling을 구현하였으며, 

ALB를 이용하여 서버 부하를 자동으로 EC2 인스턴스에 분산시켜 최상의 효과를 얻고 있습니다. 

또한, 모니터링과 테스트를 위해 grafana, pinpoint 도구들을 활용하고 있습니다. 이를 통해 서비스의 안정성과 성능을 높일 수 있습니다

<약 1분 10초>

[트러블 슈팅] [7번]

공연 예매 사이트 특성상 티켓 오픈 직후 많은 수의 Request가 몰리게 됩니다.

티켓의 수는 한정되어있기에 총 좌석 수만큼 실제 예매가 진행되어야 하고, 동시에 좌석 수와 실제 예매 진행 상황을 반영하여 데이터 무결성을 유지해야 합니다. 

그래서 저희 프로젝트는 데이터 무결성과 응답속도, TPS개선을 위한 트러블 슈팅이 진행되었습니다.

<약 28초> 

[8번]

예매하기 로직에서 동시에 여러 유저가 예매를 시도할 경우, 트랜잭션끼리 충돌이 발생하여 데이터 무결성이 지켜지지 않는 문제가 발생하였습니다. 

[9번]

이에 대해 PESSIMISTIC_WRITE LOCK을 적용하여 데이터 무결성을 보장했지만, 이로 인해 응답속도가 약 50000ms 정도로 매우 느렸습니다. 

저희는 비관적 락이 데이터베이스에서 트랜잭션이 끝날 때까지 다른 트랜잭션의 접근을 막기 때문에 속도 저하가 발생했다고 판단했습니다.

(Redis 화면) [10번]

따라서 저희는 DB에 락을 걸지 않고 “인메모리 저장소”, “싱글 스레드”, “단순 연산의 경우 원자성 보장”이라는 특성을 가진 Redis를 도입하여 속도 개선과 동시성 제어를 해결하고자 했습니다.

(35초) 

[11번]

속도 문제를 해결하기 위한 적용 과정은 다음과 같고 빨간색 박스 안에있는 로직이 속도개선의 핵심입니다. 

남은 좌석 수를 Redis에 저장하여 좌석수를 조회하고 차감하는 로직을 Redis에서 수행하게 했습니다.   

이후 예매기록은 DB에 저장되고, Redis에 저장된 남은 좌석 수는 매 분마다 Write Back 방식으로 DB에 저장됩니다. 

저희는  DB보다 속도가 월등히 빠른 Redis 저장소를 이용해 티켓 재고를 관리하게 되어 응답속도가 크게 개선되었습니다.

<약 1분 12초>

[12번]

두번째로, AutoScailing을 이용하여 성능 개선 및 비용 절감을 위한 트러블 슈팅을 진행하였습니다. 

단일 서버로는 프로젝트 목표달성이 어려울 것으로 판단되어, 부하 분산을 위해 AWS EC2 서버를 활용한 AWS Load Balancer 기능을 사용하기로 결정하였으며, Application Load Balancer를 사용하여 응답속도와 TPS를 향상시켰습니다. 

또한, 공연 예매 사이트의 특성상 예매가 집중되는 시간대에는 서버 리소스가 과다하게 사용되지만, 다른 시간대에는 서버 리소스가 낭비될 수 있다는 문제점이 있습니다. 

이에 대한 해결책으로 Auto Scaling을 적용하여 서버 인스턴스를 부하에 따라 유동적으로 Scale in / Scale out 되도록 조정함으로써, 자원 사용량을 최적화하고 비용 절감 효과를 극대화할 수 있었습니다. 

<약 1분 >

[13번]

세번째로는 APM을 활용한 병목현상 발견과 해결과정입니다. 

저희는 더 높은 응답속도를 위해 Pinpoint 모니터링 도구를 도입하여 코드레벨 까지의 세부적인 정보를 모니터링 하였습니다. 

분석 결과, 평균 응답 속도가 지나치게 느린 트랜잭션은 HikariDataSource 클래스의 getConnection() 메서드에서 속도가 지체되는 것을 발견하였습니다. 

그래서 저희는 데이터 베이스로 query를 보낼 때 conncetion을 취득하는 과정에서의 병목이 발생했다고 판단했습니다.

이를 해결하기 위해 Hikari PoolSize 수를 조절하여 적절한 수의 connection pool을 생성하고 재활용하는 전략을 사용하여 context switching 비용을 줄이고 getConnection()에 걸리는 시간을 줄였습니다. 

<약 50초 > 

[성능 개선] [14번]

저희는 트러블 슈팅 동안 각 단계에서 성능 개선의 정도를 측정하기 위해 Apache JMeter를 이용하여 동시요청수를 1초에 만명씩 증가시켜 부하테스트를 진행했고, 평균 응답속도와 TPS를 중점 지표로 삼았습니다. 

[15번]

먼저 상세 페이지 GET 읽기 요청 테스트 결과입니다. 

동시 요청 1만개의 경우, 평균 응답속도는 이전 22848ms에서 105ms 로 99.54% 개선되었으며 처리량은 176tps에서 1508tps로 7.59배 증가했습니다. 

[16번]

이렇게 빨라지게된 이유는 반복적으로 조회되는 데이터를 Redis 캐시로 조회하게 하여 데이터베이스 부하를 줄이고 응답속도도 개선하게 되었습니다.

[17번]

다음으로, 예매 로직에 대한 POST 쓰기 요청 테스트를 진행하였습니다. 

이 차트는 1초동안 jmeter 쓰레드로 동시 요청 수를 1만개 보냈을 때의 테스트 결과 값입니다.

앞서 트러블슈팅에서 언급한 예매 로직에 Redis Cache를 적용하고 성능이 크게 개선되었습니다. 

초기 결과와 최종 결과를 비교해보면, 평균 응답 속도는 49368ms에서 960ms 로 약 98% 개선되었으며, 처리량은 77tps에서 1223 tps로 15.87배 증가했습니다. 

[18번]

2000명의 동시접속자가 4개의 api에 초당 8000번의 요청을 보내는 시나리오 테스트에서는 평균 응답속도 1031ms에 처리량 1816tps를 달성하였습니다. 

[18번]

마지막으로 최종 테스트에서 동시 요청 수를 5만으로 늘린 결과입니다.

상세페이지 조회 GET 읽기 요청은 평균 응답 속도는 194ms, 처리량은 1425tps를 기록했습니다. 

예매하기 POST 쓰기 요청은 평균속도 1338ms, 처리량은 1097tps를 기록하였습니다. 

마무리 [19번]

이상으로 챌린지 2조 발표를 마치겠습니다. 

감사합니다. 

---

---

---

---

간단 소개 영상

[1번]

내 티켓은 NETicket에서! 안녕하세요! 항해99 챌린지 2조입니다.

[2번]

저희 프로젝트 Neticket은 누구나 빠르고 쉽게 티켓 예매를 할 수 있는 사이트입니다. 대규모 트랜잭션 환경에서도 안정적인 서비스를 제공하기 위해 동시에 50k이상의 트랜잭션처리, 1000TPS이상 처리량, 최소비용 이라는 목표를 설정하고 진행했습니다.

[간단시연]

neticket 메인 페이지에서는 예매가능한 공연이 오늘 날짜와 가장 가까운 순서대로 4개씩 정렬이 됩니다. 티켓팅이 시작된 공연을 클릭하면 공연에 대한 상세정보를 알 수 있고 예매를 진행하여 티켓장수를 선택 후 예매를 완료 할 수 있습니다.

[3번]

저희 프로젝트의 아키텍처는 그림과 같이 설계하였습니다.

서버 부하에 따라 EC2 인스턴스가 자동으로 확장되도록 Auto Scaling을 구현하였으며, 응답속도를 개선하기 위해 AWS에서 제공하는 ElastiCache Redis를 활용하고 있습니다. 

[4번]

이번 프로젝트를 통해 다음과 같은 성능 개선을 이뤄냈습니다.

동시에 Get 읽기 요청 1만개 테스트의 경우, 평균 응답속도는 99.54% 개선되었으며 처리량은 7.59배 증가했습니다. 

[5번]

동시에 Post 쓰기 요청 1만개 테스트의 경우, 평균 응답 속도는 약 98% 개선되었으며, 처리량은 15.87배 증가했습니다. 

[6번]

저희 프로젝트 진행과정이 궁금하시다면 2조를 찾아주세요~

# 예상질문

**"1. 팀원마다 인상깊었던 트러블 슈팅과 그 경험에서 배운것들에 대해서 설명해주세요
2. 설계 관점에서 주안점을 둔 원칙과 개발하고 운영하면서 바뀐것들이 있나요?
3. JMeter로 부하테스트를 진행하여 경계점을 발견하거나 시나리오를 서버가 감당하지 못했을때 어떻게 대처하려고 했는지 알려주세요"

"1. 팀원들끼리 협업하면서 어려운 점은 없었나요? 있었다면 어떻게 해결하셨나요?
2. 깃헙 이슈를 많이 활용하신 것 같은데 프로젝트를 진행하면서 어떤 방식으로 소통하셨는지, 컨벤션 등에 대해 말씀해주세요
3. 동시성 제어가 필요했던 상황과 적용 과정을 간단하게 설명해주세요"

"1. 팀원 개개인이 팀에서 맡은 내용을 설명해주세요.
2. 코드를 작성할때 중요하다고 생각하는점을 서술해주세요.
3. 그 내용이 본인 프로젝트 어느곳에 녹아있는지 서술해주세요."

"1. 업무를 어떤식으로 분장을 하셨나요?
2. 코드를 작성할때 어떤점을 가장 중요시 생각하고 작성하셨나요?
3. 코드 작성 말고, 협업을 할때는 어떤점을 가장 중요시 생각하셨나요?"**

**"1. 코드를 작성할때 어떤점을 가장 중요시 생각하고 작성하셨나요?
2. 코드 작성 말고, 협업을 할때는 어떤점을 가장 중요시 생각하셨나요?
3. 가장 구현하기 어려웠던 로직에 대해서 설명해주세요."

"1. 락을 처리하는 로직을 반복문으로 처리하셨는데, 재시도 횟수를 지정하지 않고 반복문으로 처리한 이유가 무엇인가요?
2. 현업 개발자를 뛰어넘을 정도로 프로젝트가 화려한데 팀원분들 모두 개발자로 일한 경험이 있으신가요?
3. 브로슈어에 작성한 내용들은 처음부터 생각을 해두고 작성하신건가요? 아니면 실전프로젝트가 끝나고 서치해서 작성하신 건가요?"

"1. 동시성 문제를 해결하기위해 가장 신경썻던 부분이 어떤건가요?
2. 프로젝트 진행하면서 가장 힘들게 해결한 문제가 있나요?
3. Spring Transactional로 인한 spin lock 문제가 어떤 문제였는지 글로는 이해가 잘 되지 않아서 자세히 설명해주실 수 있을까요?"

"1. 가장 구현하기 어려웠던 기능이 무엇인지
2. 협업 과정에서 어려웠던 점이나 좋았던 점
3. 실제 서비스는 아니지만 서비스를 해봄으로써 어떤 점을 느꼈는지 어떤 점이 좋았는지"**